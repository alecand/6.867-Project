{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from skimage.measure import block_reduce\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "f = fetch_olivetti_faces(shuffle = False)\n",
    "face_images = f.images\n",
    "face_rows = f.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.imshow(face_images[i], cmap = plt.cm.gray)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "people_list = np.loadtxt('people.txt').astype(int)\n",
    "ok_dirs = []\n",
    "\n",
    "for i in range(1,1001):\n",
    "    if not i in people_list:\n",
    "        ok_dirs.append(r'Flickr Images\\im' + str(i) + '.jpg')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import color, io\n",
    "\n",
    "img_list = [color.rgb2gray(io.imread(ok_dirs[i])) for i in range(len(ok_dirs))][:500]\n",
    "shape_list = [io.imread(ok_dirs[i]).shape for i in range(len(ok_dirs))]\n",
    "\n",
    "# plt.imshow(img_list[10],cmap = plt.cm.gray)\n",
    "# plt.show()\n",
    "# len(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "dim_param = 64\n",
    "\n",
    "gen_image_list = []\n",
    "\n",
    "rand_subs = []\n",
    "\n",
    "for shape in shape_list:\n",
    "    xs = np.random.randint(0, shape[0]-dim_param, size = 5)\n",
    "    ys = np.random.randint(0, shape[1]-dim_param, size = 5)\n",
    "    rand_subs.append(zip(xs, ys))\n",
    "\n",
    "for i in range(len(img_list)):\n",
    "    for dim in rand_subs[i][:4]:\n",
    "        gen_image_list.append(img_list[i][dim[0]:dim[0]+dim_param, dim[1]:dim[1]+dim_param])\n",
    "        \n",
    "    \n",
    "for i in range(10):\n",
    "    plt.imshow(gen_image_list[i], cmap = plt.cm.gray)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = list(face_images)[:300] * 5\n",
    "X_train.extend(gen_image_list[:1500])\n",
    "Y_train = [1 for _ in range(1500)]\n",
    "Y_train.extend([0 for _ in range(1500)])\n",
    "X_train_lr = np.array(X_train)\n",
    "X_train_lr = X_train_lr.reshape(-1, X_train_lr.shape[0]).T\n",
    "\n",
    "\n",
    "\n",
    "X_test = list(face_images)[300:] * 5\n",
    "X_test.extend(gen_image_list[1500:])\n",
    "Y_test = [1 for _ in range(500)]\n",
    "Y_test.extend([0 for _ in range(500)])\n",
    "X_test_lr = np.array(X_test)\n",
    "X_test_lr = X_test_lr.reshape(-1, X_test_lr.shape[0]).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_baseline_model = LogisticRegression(C =10)\n",
    "lr_baseline_model.fit(X_train_lr, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coef_mat = lr_baseline_model.coef_.reshape(64,64)\n",
    "norm_coef_mat = (coef_mat - np.min(coef_mat))/(np.max(coef_mat) - np.min(coef_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(norm_coef_mat, cmap = plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_baseline_model.score(X_test_lr[:100], Y_test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(sum(i for i in f.images)/len(f.images), cmap = plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
